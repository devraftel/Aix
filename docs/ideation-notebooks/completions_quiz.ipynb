{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.openai_sdk.seed_config import GENERATE_QUESTIONS_ASSISTANT_SEED, mock_generated_questions, mock_rag_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "_: bool = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "client: OpenAI = OpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def generate_Questions(quiz_title: str, questions_to_generate: int, question_type:list, content: str):\n",
    "    \"\"\"\n",
    "    Grade Open Text Question\n",
    "    \"\"\"\n",
    "    try:\n",
    "        seed_prompt = f\"\"\"Create a 10 minutes 'Generative AI' Quiz that will have `4` Questions. The Questions type will include: 1. \"single_select_mcq\" 2. \"multi_select_mcq\" and \"open_text_question\". The Quiz will be easy and the questions generated shall follow: {mock_rag_content}\"\"\"\n",
    "        user_prompt = f\"\"\"Create a 30 minutes {quiz_title} Quiz that will have {questions_to_generate} Questions. The Questions type will include: {question_type}. The Quiz will be easy and the questions generated shall follow: {content}\"\"\"\n",
    "        # 1. Call OpenAI API to grade the question\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": GENERATE_QUESTIONS_ASSISTANT_SEED},\n",
    "                {\"role\": \"user\", \"content\": seed_prompt},\n",
    "                {\"role\": \"assistant\", \"content\": json.dumps({'questions': mock_generated_questions})},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            )\n",
    "        \n",
    "        json_str = response.choices[0].message.content\n",
    "        print(json_str)\n",
    "        \n",
    "        if json_str is None:\n",
    "            raise ValueError(\"Question Grading Failed\")\n",
    "        \n",
    "        # 2. Parse the response\n",
    "        obj_out: dict[str, list[str]] = json.loads(json_str)\n",
    "\n",
    "        return obj_out\n",
    "    except Exception as e:\n",
    "        raise ValueError(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = generate_Questions(\"Generative AI\", 4, [\"single_select_mcq\", \"multi_select_mcq\", \"open_text_question\"], mock_rag_content)\n",
    "\n",
    "print(\"\\n------------- questions\\n\", questions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
